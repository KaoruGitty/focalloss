# 損失関数比較：3クラス分類における数式定義

正解クラスを $P_{correct}$、間違いクラスを $P_{wrong}$ と定義します。
（3クラスの場合、正解を $P_0$、間違いを $P_1, P_2$ とします）

---

## 1. 通常のクロスエントロピー (Standard Cross Entropy)
最も一般的な形式。正解クラスの確率のみを最大化します。

$$Loss_{CE} = - \log(P_{correct})$$

* **特性**: 正解以外はすべて平等に扱う。
* **重み**: 正解に $w=1$、不正解に $w=0$ がかかっている状態。

---

## 2. 旧型コスト考慮損失 (Old Cost-Sensitive Loss)
間違いクラスの確率を直接対数に入れた形式。今回の「バグ」の原因となった式です。

$$Loss_{old} = -(a \log P_{correct} + \sum b_j \log P_{wrong, j})$$

* **特性**: $b_j$ が大きすぎると（$a < b$）、間違いクラスに自信を持つほどロスが減ってしまう。
* **欠点**: 間違い 100% 地点が「報酬（無限のマイナス）」として機能し、AIが逆走する。

---

## 3. 新案コスト考慮損失 (New Cost-Sensitive Loss / CSL)
間違いクラスを「否定」する形式。数学的に最も安定し、意図を反映できます。

$$Loss_{new} = -(a \log P_{correct} + \sum b_j \log(1 - P_{wrong, j}))$$

* **特性**: 間違いクラスに自信を持つほどロスが **正の無限大** に発散（爆発的な罰金）。
* **利点**: $a$ と $b$ の大小関係に関わらず、AIは必ず「正解」の方向へ誘導される。

---

## 数学的挙動の比較（サマリー）

| 関数 | 間違い $P_{wrong} \to 1$ 時の挙動 | AIの反応 |
| :--- | :--- | :--- |
| **通常のCE** | ロスが微増（正解が減るため） | 正解を探す |
| **旧型 (a < b)** | **ロスがマイナス無限大に発散** | **積極的に間違える** |
| **新型 (CSL)** | **ロスがプラス無限大に発散** | **その間違いを絶対避ける** |

